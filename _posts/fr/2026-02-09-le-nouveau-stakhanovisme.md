---
layout: post
title: "Le nouveau stakhanovisme"
date: 2026-02-09
categories: [ai, work, philosophy, organization, series]
excerpt: 'Le mouvement stakhanoviste célébrait des ouvriers modèles pour relever les quotas de tous les autres. Les entreprises AI-native rejouent le même scénario.'
header_image: "https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Stakhanov.JPG/1600px-Stakhanov.JPG"
header_image_alt: "Alexeï Stakhanov, mineur de charbon soviétique et héros du mouvement stakhanoviste"
header_image_credit: "Soviet Archives"
header_image_credit_url: "https://commons.wikimedia.org/wiki/File:Stakhanov.JPG"
header_image_source: "Wikimedia Commons"
header_image_source_url: "https://commons.wikimedia.org"
ref: the-new-stakhanovism
redirect_from:
  - /2026/02/09/le-nouveau-stakhanovisme/
lang: fr
---

## La fable

En 1935, Alexeï Stakhanov extrait 102 tonnes de charbon en un seul poste, soit 14 fois la norme. L'Union soviétique en fait un héros, et le mouvement stakhanoviste naît. Des ouvriers modèles dépassent les quotas pour prouver que le système fonctionne.

Ce que la propagande ne mentionne pas, ce sont les équipes qui lui dégagent le terrain, préparent ses outils et retirent les obstacles. Il n'est pas seul, il est *mis en scène*.

Cette mise en scène sert deux objectifs : légitimer le système, et relever les quotas pour tous les autres. « Si Stakhanov y arrive, pourquoi pas toi ? »

En juin 2025, Elena Verna, Head of Growth chez Lovable, publie [The Rise of the AI-Native Employee](https://www.elenaverna.com/p/the-rise-of-the-ai-native-employee). Elle y décrit un modèle radical : des petites équipes sans process ni handoff, pas de middle management et l'IA comme outil par défaut. Construire plutôt que coordonner, avec 35 personnes pour 80 millions de dollars d'ARR. Le #AINativeEmployeeEra.

Huit mois plus tard, Lovable met Lazar Jovanovic sur [le podcast de Lenny](https://www.lennysnewsletter.com/p/getting-paid-to-vibe-code), le plus grand podcast produit de la tech. C'est leur « premier vibe codeur professionnel » : il n'a aucune formation en développement et livre des produits en production en utilisant uniquement l'IA. La thèse faite chair.

Pendant ce temps, Lovable affiche des dizaines de postes ouverts : GTM Operations, Recruitment Coordinator, Customer Success Manager, Enterprise Account Executive et Security Engineer avec « 5 ans et plus en environnements cloud-native ». Ne sont-ce pas exactement les rôles qu'Elena décrivait comme condamnés ?

Lazar n'est pas ingénieur et ne construit pas les systèmes de Lovable ; il montre ce qu'on peut faire avec l'IA. Derrière ses démos, il y a une infrastructure maintenue par des platform engineers, une sécurité gérée par des spécialistes, des contrats enterprise signés par des AE expérimentés et une machine GTM portée par des opérateurs seniors. Lovable est le cas le plus visible d'un schéma plus large. Klarna a remplacé 700 agents de service client par de l'IA et en a fait un communiqué de presse. Duolingo a coupé ses contractuels après avoir étendu ses capacités IA et l'a présenté comme une évolution naturelle. La fable est toujours la même : le système fonctionne, et l'humain est optionnel.

Ça ne réfute pas la thèse, un SaaS comparable à ce stade emploierait peut-être un millier de personnes, et Lovable construit peut-être réellement un modèle plus léger. Mais il y a un écart entre une transition et une fable. Quand l'effectif réel d'une entreprise s'éloigne autant du récit qu'elle projette, on ne décrit plus l'avenir, on le met en scène.

Le parallèle n'est pas politique, personne n'a fini au goulag. Il est *narratif* : un ouvrier modèle rendu visible, une infrastructure rendue invisible et une norme imposée à tous les autres.

## Le zèle

Mais la fable ne fonctionne que si on oublie ce qu'elle comprime. Et ce qui se comprime en premier, c'est la nature même du travail humain.

Prenons un ouvrier sur une chaîne d'assemblage automobile. Il doit visser un boulon dans un filetage. Le boulon ne rentre pas. Il en essaie un deuxième, puis un troisième, aucun ne passe. La procédure dit d'arrêter la chaîne. Mais arrêter la chaîne coûte des dizaines de milliers d'euros par minute. Alors il court chercher un seau d'huile, trempe les boulons dedans et les force un par un. La chaîne ne s'arrête pas. Le produit sort, personne ne sait. C'est ça, le [travail vivant](/fr/2026/01/01/la-triche-qui-fait-tourner-le-monde/).

L'écart *est* le travail, et cet écart est une forme de zèle, non pas l'obéissance à l'instruction mais la loyauté envers le résultat. C'est le zèle productif, celui qui dit : je sais ce qu'on m'a demandé, mais voilà ce qu'il faut vraiment faire.

Il en existe un autre : la réunion inutile convoquée par loyauté envers le process, le contournement politique, la code review rituelle que personne ne lit vraiment et le rapport hebdomadaire qui finit dans le vide. C'est le zèle parasitaire, la dévotion au rituel du travail plutôt qu'à sa substance.

Un agent IA supprime les deux dans le même geste. Il n'a pas de corps, pas de friction avec le réel. Quand le boulon ne rentre pas, il escalade, bloque ou hallucine une solution. Il ne trempe rien dans l'huile, il ne *triche* pas. Chaque écart d'un agent a été anticipé par son concepteur, alors que le zèle productif, par définition, dépasse ce que quiconque a pré-configuré. Mais l'agent ne convoque pas non plus de réunions inutiles. Il supprime la déviance productive et la déviance parasitaire de façon identique, car depuis l'intérieur d'un system prompt, elles se ressemblent.

« Pas de process, pas de handoff, juste construire » est la [grève du zèle](/fr/2026/01/01/la-triche-qui-fait-tourner-le-monde/) de l'IA, non pas l'obéissance pour ralentir mais l'obéissance pour accélérer. Dans les deux cas, l'espace où le jugement humain corrige l'écart entre l'instruction et la réalité se comprime.

Quand l'agent automatise tout, qui est garant du zèle ? Pas le parasitaire, mais le productif, celui qui sent que le boulon ne rentre pas avant que le produit ne sorte.

Quelqu'un doit décider ce que l'agent sait, ce qu'il ignore et où il s'arrête. Quelqu'un configure le cadre, et ce quelqu'un est peut-être déjà la personne la plus importante du bâtiment.

## La compression

Le parallèle stakhanoviste va au-delà du récit. Le mouvement servait aussi une fonction économique précise en relevant les quotas. Si Stakhanov pouvait faire 14 fois la norme, la norme pouvait monter. Chaque ouvrier était désormais mesuré à l'aune du modèle, et la productivité n'était pas redistribuée, elle était *extraite*.

Le récit AI-native reprend la même logique dans un autre emballage. Quand une entreprise démontre qu'une personne avec l'IA peut faire le travail de quatre, deux choses peuvent arriver : produire quatre fois plus, ou licencier trois sur quatre.

Les deux arrivent, mais le récit dominant dans le discours AI-native récompense l'extraction et invisibilise la redistribution. L'ouvrier modèle passe sur un podcast, et ceux dont les rôles sont devenus « redondants » mettent à jour leur LinkedIn en silence.

C'est ça, la compression. Pas la compression du temps d'exécution (cette partie est réelle, et souvent bienvenue), mais la compression de la force de travail en une unité plus serrée, plus rapide et plus surveillée, où la norme a été recalibrée par une démo sur un podcast. Où « si Lazar y arrive » devient discrètement « pourquoi on a besoin de toi ? »

Mais la compression ne s'arrête pas à l'extraction. Elle recalibre aussi ce que chacun considère comme un rythme normal. Dans une équipe, celui qui utilise l'IA efficacement est sensiblement plus productif que celui qui ne l'utilise pas. Chacun développe sa propre martingale, son propre setup pour produire au-delà de ce que le rythme d'avant permettait. Le volume augmente, les attentes suivent, et la fatigue en fin de journée monte parce que la barre est plus haute. À un moment, il faudra choisir : le nouveau Stakhanov, celui qui produit davantage avec son setup IA, sera préféré à l'autre. C'est exactement la même mécanique : le travailleur modèle recalibre la norme pour tous les autres.

Dans ce contexte, Lazar pose une question radicale. Il n'a aucune formation d'ingénieur et ne construit pas les systèmes de Lovable ; il exploite ce qu'on peut faire avec. Mais si on le prend au sérieux, quel est encore l'argument pour l'ingénieur diplômé qui empile des architectures de plus en plus complexes ? Ce n'est pas tranché, mais la question est posée.

Et la personne qui configure l'agent qui donne le rythme ? C'est elle qui décide, en pratique, à quoi ressemble la « productivité normale ». Pas en fixant des quotas, mais en fixant le contexte.

## La banalité de la configuration

Ce pouvoir de configurer le cadre dans lequel tout le monde opère n'est pas nouveau. Hannah Arendt a identifié un mécanisme précis, celui du fonctionnaire diligent qui exécute sans réfléchir à la finalité de ce qu'il exécute. Pas un monstre mais un bureaucrate, quelqu'un qui « fait de l'ingénierie » alors qu'il fait de l'idéologie. Le parallèle n'est pas moral, il est structurel.

Appelons ça la banalité de la configuration. Quelqu'un, en ce moment même, configure les limites d'un agent IA avec lequel chaque employé interagit quotidiennement. Ce quelqu'un conçoit l'architecture cognitive de l'organisation et décide de ce qui est pensable. Ce rôle n'a pas de nom, pas de gouvernance et pas de trace d'audit. Le fait qu'il soit invisible est précisément ce qui le rend puissant.

Ce sujet dépasse le cadre de cet article. Je l'explore en détail dans [Qui écrit la constitution des machines ?](/fr/2026/02/18/qui-ecrit-la-constitution-des-machines/), à travers la Constitution de Claude, les chartes octroyées et la gouvernance invisible des déploiements IA en entreprise.

## Ce qui reste ouvert

Le système soviétique ne s'est pas effondré parce qu'il a échoué, mais parce qu'il a [trop bien réussi](/fr/2026/01/04/effondrement-par-obeissance/), sur le papier. Des rapports parfaits, zéro vérité. L'écart entre le prescrit et le réel a grandi jusqu'à ce que le système ne puisse plus se voir lui-même.

Cet article s'ancre sur trois axes. La fable montre un ouvrier modèle rendu visible pendant que l'infrastructure reste invisible. Le zèle révèle ce qui se perd quand on automatise sans distinguer la déviance productive de la déviance parasitaire. La compression expose ce qui monte quand la norme est recalibrée par une démo sur un podcast. La banalité de la configuration est le pont vers la question suivante, celle de savoir qui conçoit le cadre et avec quelle légitimité.

Les organisations qui survivront à cette transition ne seront ni les plus rapides, ni les plus nostalgiques. Ce seront celles qui auront compris que le zèle productif (le boulon dans l'huile, l'écart qui sauve le produit et le jugement qu'aucun system prompt ne peut encoder) ne peut pas être automatisé, seulement écrasé. Et que la différence entre le mou qui gaspille et le mou qui sauve est plus floue que ce que n'importe quel cadre d'optimisation peut percevoir.
