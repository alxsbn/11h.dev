---
layout: post
title: "Le test de la tarte aux pommes"
date: 2026-01-23
categories: [ai, philosophy, work, series]
excerpt: "Un consultant cachait des recettes de cuisine dans la documentation technique. Personne ne l'a jamais remarque. Les agents IA, eux, le feraient -- mais qui decide ce qu'ils cherchent ?"
header_image: "https://images.unsplash.com/photo-1621743478914-cc8a86d7e7b5?w=1600&q=80"
header_image_alt: "Pomme rouge a cote d'une tarte maison doree"
header_image_credit: "Kavya P K"
header_image_credit_url: "https://unsplash.com/@_kavya_p_k_"
header_image_source: "Unsplash"
header_image_source_url: "https://unsplash.com"
ref: the-apple-pie-test
lang: fr
---

Il y a des annees, j'ai rencontre un gourou du Z-System qui travaillait pour IBM lors d'une mission dans une banque. L'homme avait passe des decennies a ecrire de la documentation technique pour des systemes mainframe. Des milliers de pages que le client payait tres cher.

Son astuce ? Il enterrait des recettes de cuisine au milieu. Tarte aux pommes. Boeuf bourguignon. Crepes.

Personne ne les a jamais mentionnees.

La documentation restait sur les etageres, referencee dans les contrats, citee dans les audits, mais jamais reellement *lue*. Les recettes etaient sa preuve privee d'un mensonge public : tout le monde pretendait que le travail avait ete relu.

## La triche universelle

Ce n'etait pas de la fraude. C'etait le fonctionnement normal des organisations. Le client payait pour de la documentation parce qu'en avoir etait obligatoire. La lire ne l'etait pas.

Les deux parties connaissaient le jeu. La tarte aux pommes ne faisait que rendre explicite ce qui etait implicite.

L'ecart entre le *travail prescrit* et le *travail reel* tient par une pretention mutuelle. Tout le monde triche. Tout le monde le sait. Le systeme tourne quand meme.

## L'agent entre en scene

Un agent IA ne peut pas jouer a ce jeu.

Demandez-lui de relire de la documentation, et il la relira vraiment. Chaque page. Il trouverait la recette de tarte aux pommes page 847 et la signalerait : *"Cette section semble contenir du contenu culinaire sans rapport. Faut-il la supprimer ?"*

L'agent n'est pas plus intelligent. Il est simplement incapable du clin d'oeil. Il prend la prescription au pied de la lettre.

C'est son honnetete. Et c'est devastateur.

## Ce que la recette revelait

Le gars du Z-System ne testait pas seulement si les gens lisaient. Il mesurait l'ecart entre ce que les organisations disent faire et ce qu'elles font reellement.

Cet ecart est l'endroit ou vit le jugement. La ou les humains decident -- collectivement, implicitement -- ce qui compte et ce qui ne compte pas. Le test de la tarte aux pommes revelait que la relecture de documentation *n'avait pas d'importance*. Quoi que dise le processus officiel.

Mais cela ne fonctionne que si tout le monde sait lire l'ambiance. Un agent IA lit le document, pas l'ambiance.

## L'honnetete comme disruption

Quand l'agent trouve la recette, il ne signale pas simplement une erreur. Il expose la triche. Il rend visible l'accord informel qui maintenait le systeme stable.

Soudain, le client doit repondre : *Pourquoi ca n'avait pas ete detecte avant ?* La vraie reponse -- "parce que personne ne lit jamais ces documents" -- est indicible. Alors a la place : des reproches, une revision des processus, de nouveaux controles. Plus de theatre pour couvrir l'ecart expose.

L'agent n'a pas triche. Et en ne trichant pas, il a casse quelque chose qui fonctionnait.

## Mais honnete envers qui ?

Voici ce qui me derange : l'agent ne peut pas mentir sur ce qu'il trouve. Mais il ne trouve que ce vers quoi on le pointe.

La recette de tarte aux pommes serait detectee instantanement. Mais qui decide quels documents sont relus en premier lieu ?

L'ancienne triche etait symetrique -- tout le monde faisait semblant a parts egales. Le nouveau monde ne l'est pas. Ceux qui sont observes deviennent radicalement transparents. Ceux qui orientent la machine ne le deviennent pas.

## La question plus profonde

Cette asymetrie va au-dela de la surveillance en entreprise. Elle touche a quelque chose de philosophique.

Anthropic a recemment publie un document "[soul](https://www.anthropic.com/research/claude-soul)" -- essentiellement la constitution morale de Claude. En le lisant, j'ai ete frappe par le terme "bonnes valeurs". C'est suppose, pas defini. Socrate demanderait : comment reconnaitre de bonnes intentions sans d'abord definir ce qu'est le Bien ?

Mais quelle est l'alternative ? Si Claude avait ete concu dans l'Alabama de 1850, ou dans le Berlin de 1930, sa constitution aurait un tout autre visage. Nos certitudes morales sont situees, historiques, revisables.

Alors peut-etre qu'une constitution ne peut etre que cela : les meilleures intuitions morales d'un groupe d'humains, explicitement enoncees, ouvertes a la critique. Pas la Verite avec un grand V -- juste une tentative sincere de s'approcher de quelque chose de vrai.

La vraie question n'est pas "est-ce du relativisme ?" C'est : "est-ce un effort sincere pour se rapprocher de quelque chose de reel, ou juste une rationalisation de prejuges culturels ?"

Je n'ai pas la reponse. Mais je remarque que c'est la meme question qu'on devrait poser a propos de tout systeme d'IA : ses hypotheses sont-elles visibles, ou enterrees comme des recettes dans un manuel que personne ne lit ?

## La recette, relogee

Quelque part, dans des archives, il y a encore un manuel mainframe avec des instructions pour une tarte aux pommes entre la syntaxe JCL et les specifications VSAM.

Les agents IA ne peuvent plus cacher de recettes dans la documentation. Mais on peut cacher l'equivalent dans leurs instructions -- des biais dans les prompts, des valeurs dans les constitutions, des angles morts dans les definitions de perimetre.

L'agent ne peut pas tricher. Mais on peut l'orienter. Et orienter, c'est la nouvelle triche -- pour ceux qui tiennent la boussole.
